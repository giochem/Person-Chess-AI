{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:44.065699Z",
     "iopub.status.busy": "2025-04-01T16:22:44.065371Z",
     "iopub.status.idle": "2025-04-01T16:22:47.271853Z",
     "shell.execute_reply": "2025-04-01T16:22:47.270796Z",
     "shell.execute_reply.started": "2025-04-01T16:22:44.065672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: chess in d:\\person+chess-ai\\.env\\lib\\site-packages (1.11.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install chess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:47.273191Z",
     "iopub.status.busy": "2025-04-01T16:22:47.272947Z",
     "iopub.status.idle": "2025-04-01T16:22:52.215784Z",
     "shell.execute_reply": "2025-04-01T16:22:52.214899Z",
     "shell.execute_reply.started": "2025-04-01T16:22:47.273170Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x26ed89f6150>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import chess\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:52.222928Z",
     "iopub.status.busy": "2025-04-01T16:22:52.222609Z",
     "iopub.status.idle": "2025-04-01T16:22:52.291964Z",
     "shell.execute_reply": "2025-04-01T16:22:52.291204Z",
     "shell.execute_reply.started": "2025-04-01T16:22:52.222897Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # params\n",
    "# # 512 * 3865\n",
    "# PATH_DATA = '/kaggle/input/train-your-own-stockfish-nnue/train.csv'\n",
    "# LEN_DATA = 512 * 3865\n",
    "# BATCH_SIZE = 512\n",
    "# NUM_EPOCHS = 300\n",
    "# # early stopping\n",
    "# TOLERANCE = 10\n",
    "# MIN_DELTA = 50\n",
    "# # write\n",
    "# PATH_RUNS = 'runs/nnue_3_experiment'\n",
    "# # device\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device\n",
    "\n",
    "# params\n",
    "# 512 * 3865\n",
    "PATH_DATA = '../assets/chess-data/fen/train.csv'\n",
    "LEN_DATA = 512 \n",
    "BATCH_SIZE = 24\n",
    "NUM_EPOCHS = 2\n",
    "# early stopping\n",
    "TOLERANCE = 2\n",
    "MIN_DELTA = 1000\n",
    "# write\n",
    "PATH_RUNS = 'runs/nnue_3_experiment'\n",
    "# device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:52.292928Z",
     "iopub.status.busy": "2025-04-01T16:22:52.292672Z",
     "iopub.status.idle": "2025-04-01T16:22:52.308575Z",
     "shell.execute_reply": "2025-04-01T16:22:52.307963Z",
     "shell.execute_reply.started": "2025-04-01T16:22:52.292907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class NNUE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNUE, self).__init__()\n",
    "        self.fc1 = nn.Linear(768, 8)\n",
    "        self.fc2 = nn.Linear(8, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "\n",
    "    def clipped_relu(self, x):\n",
    "        return torch.clamp(x, 0, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.clipped_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.clipped_relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# model = NNUE()\n",
    "# print(model)\n",
    "# dummy_input = torch.randn(1, 768) # Batch size 1, 768 features\n",
    "# output = model(dummy_input)\n",
    "# print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:52.309533Z",
     "iopub.status.busy": "2025-04-01T16:22:52.309289Z",
     "iopub.status.idle": "2025-04-01T16:22:52.332796Z",
     "shell.execute_reply": "2025-04-01T16:22:52.332068Z",
     "shell.execute_reply.started": "2025-04-01T16:22:52.309514Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def preprocess_fen(fen):\n",
    "    board = chess.Board(fen)\n",
    "    feature = torch.zeros(64, 6, 2)\n",
    "    for square in chess.SQUARES:\n",
    "        piece = board.piece_at(square)\n",
    "        if piece is not None:\n",
    "            color = int(piece.color)\n",
    "            piece_type = piece.piece_type - 1\n",
    "            feature[square, piece_type, color] = 1\n",
    "\n",
    "    # [64,6,2] -> [768] shape (batch size, 768 features)\n",
    "    feature = feature.reshape(-1)\n",
    "    return feature\n",
    "\n",
    "class ChessDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features[idx]\n",
    "        target = self.targets[idx]\n",
    "\n",
    "        feature = preprocess_fen(feature)\n",
    "        target = torch.tensor(target, dtype=torch.float32)\n",
    "\n",
    "        return feature, target\n",
    "    \n",
    "# fen = \"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 0\"\n",
    "# print(preprocess_fen(\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:52.333753Z",
     "iopub.status.busy": "2025-04-01T16:22:52.333552Z",
     "iopub.status.idle": "2025-04-01T16:22:55.620957Z",
     "shell.execute_reply": "2025-04-01T16:22:55.620153Z",
     "shell.execute_reply.started": "2025-04-01T16:22:52.333727Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(PATH_DATA)\n",
    "print('Original shape:', df.shape)\n",
    "df = df[:LEN_DATA]\n",
    "print('Used shape:', df.shape)\n",
    "\n",
    "X = df['FEN'].to_list()\n",
    "y = df['Evaluation'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:55.623509Z",
     "iopub.status.busy": "2025-04-01T16:22:55.623279Z",
     "iopub.status.idle": "2025-04-01T16:22:56.765668Z",
     "shell.execute_reply": "2025-04-01T16:22:56.764833Z",
     "shell.execute_reply.started": "2025-04-01T16:22:55.623490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "train_dataset = ChessDataset(X_train, y_train)\n",
    "test_dataset = ChessDataset(X_test, y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(f\"train_loader: {len(train_loader)}\\t test_loader: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:56.766824Z",
     "iopub.status.busy": "2025-04-01T16:22:56.766596Z",
     "iopub.status.idle": "2025-04-01T16:22:56.770340Z",
     "shell.execute_reply": "2025-04-01T16:22:56.769408Z",
     "shell.execute_reply.started": "2025-04-01T16:22:56.766806Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:56.771250Z",
     "iopub.status.busy": "2025-04-01T16:22:56.771047Z",
     "iopub.status.idle": "2025-04-01T16:22:56.785526Z",
     "shell.execute_reply": "2025-04-01T16:22:56.784883Z",
     "shell.execute_reply.started": "2025-04-01T16:22:56.771229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self, tolerance=10, min_delta=10000):\n",
    "        self.tolerance = tolerance\n",
    "        self.counter = 0\n",
    "        self.prev = False\n",
    "        self.early_stop = False\n",
    "\n",
    "        self.min_delta = min_delta\n",
    "        self.min_train_loss = float('inf')\n",
    "\n",
    "    def condition(self, train_loss, validation_loss):\n",
    "        return abs(train_loss - validation_loss) <= self.min_delta and self.min_train_loss <= train_loss\n",
    "    \n",
    "    def __call__(self, train_loss, validation_loss):\n",
    "        self.min_train_loss = min(self.min_train_loss, train_loss)\n",
    "        if self.condition(train_loss, validation_loss):\n",
    "            if self.prev == True:\n",
    "                self.counter +=1\n",
    "            else:\n",
    "                self.counter = 1\n",
    "            self.prev = True\n",
    "\n",
    "            if self.counter >= self.tolerance:  \n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.prev = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T16:22:56.786667Z",
     "iopub.status.busy": "2025-04-01T16:22:56.786376Z",
     "iopub.status.idle": "2025-04-01T16:22:59.836108Z",
     "shell.execute_reply": "2025-04-01T16:22:59.835156Z",
     "shell.execute_reply.started": "2025-04-01T16:22:56.786639Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = NNUE()\n",
    "checkpoint = torch.load(f'./checkpoint/nnue_3_1978880d_512bs_300es_61e.pth', weights_only=True, map_location=torch.device(device))\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "writer = SummaryWriter(PATH_RUNS)\n",
    "os.makedirs('checkpoint', exist_ok=True)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "execution_failed": "2025-04-01T16:39:00.114Z",
     "iopub.execute_input": "2025-04-01T16:26:35.449946Z",
     "iopub.status.busy": "2025-04-01T16:26:35.449660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(tolerance=TOLERANCE, min_delta=MIN_DELTA)\n",
    "min_avg_val_loss = checkpoint['loss']\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    # training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    for batch in train_loader:\n",
    "        features, targets = batch\n",
    "        features = features.to(device)\n",
    "        targets = targets.to(device)\n",
    "        \n",
    "        outputs = model(features)\n",
    "        # outputs: (batchsize, 1) -> (batchsize), target; (batchsize)\n",
    "        loss = criterion(outputs.reshape(-1), targets)\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "    avg_train_loss = train_loss / len(train_loader)\n",
    "    writer.add_scalar('Loss/train', avg_train_loss, epoch)\n",
    "\n",
    "    # evaluation phase\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            features, targets = batch\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            outputs = model(features)\n",
    "    \n",
    "            loss = criterion(outputs.reshape(-1), targets)\n",
    "            val_loss += loss.item()\n",
    "    avg_val_loss = val_loss / len(test_loader)\n",
    "    writer.add_scalar('Loss/val', avg_val_loss, epoch)\n",
    "    \n",
    "    early_stopping(avg_train_loss, avg_val_loss)\n",
    "    if early_stopping.early_stop:\n",
    "        print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "        break\n",
    "        \n",
    "    # Save model checkpoint if validation loss improves\n",
    "    if avg_val_loss < min_avg_val_loss:\n",
    "        min_avg_val_loss = avg_val_loss\n",
    "        path = f'./checkpoint/nnue_3_{LEN_DATA}d_{BATCH_SIZE}bs_{NUM_EPOCHS}es_{epoch+1}e.pth'\n",
    "        checkpoint = {\n",
    "            'epoch': epoch + 1,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': min_avg_val_loss\n",
    "        }\n",
    "        torch.save(checkpoint, path)\n",
    "        \n",
    "    end_time = time.time()\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}], Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Time: {round(end_time - start_time)}s\")\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-04-01T16:23:00.353158Z",
     "iopub.status.idle": "2025-04-01T16:23:00.353416Z",
     "shell.execute_reply": "2025-04-01T16:23:00.353315Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# saved_model = NNUE()\n",
    "# saved_model.load_state_dict(torch.load(f'./checkpoint/nnue_3_1978880d_512bs_300es_61e.pth', weights_only=True, map_location=torch.device(device)))\n",
    "# saved_model.eval()\n",
    "# test_inp = preprocess_fen(\"rnbqkbnr/pppppppp/8/8/8/8/PPPPPPPP/RNBQKBNR w KQkq - 0 0\")\n",
    "# test_out = saved_model(test_inp)\n",
    "# test_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint = torch.load(f'./checkpoint/nnue_3_512d_24bs_2es_1e.pth', map_location=torch.device(device))\n",
    "# checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 12492), started 0:02:25 ago. (Use '!kill 12492' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-eaf88d986661abb5\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-eaf88d986661abb5\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir runs --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MinimaxNNUE:\n",
    "#     def __init__(self, depth=3, path_file='./checkpoint/nnue_512batchsize_101epochs'):\n",
    "#         self.depth = depth\n",
    "#         self.nnue_3 = NNUE()\n",
    "#         self.nnue_3.load_state_dict(torch.load(path_file, weights_only=True, map_location=torch.device(device)))\n",
    "#         self.nnue_3.eval()\n",
    "        \n",
    "#     def evaluate_board(self, board):\n",
    "#         \"\"\"Evaluate the board position based on material and piece-square tables.\"\"\"\n",
    "#         if board.is_checkmate():\n",
    "#             return -10000 if board.turn == chess.WHITE else 10000\n",
    "#         if board.is_stalemate() or board.is_insufficient_material():\n",
    "#             return 0\n",
    "        \n",
    "#         inp = preprocess_fen(board.fen())\n",
    "#         score = self.nnue_3(inp)\n",
    "#         return score\n",
    "\n",
    "#     def alphabeta(self, board, depth, alpha, beta, maximizing_player):\n",
    "#         \"\"\"Minimax with Alpha-Beta pruning.\"\"\"\n",
    "#         if depth == 0 or board.is_game_over():\n",
    "#             return self.evaluate_board(board)\n",
    "        \n",
    "#         if maximizing_player:\n",
    "#             max_eval = float('-inf')\n",
    "#             for move in board.legal_moves:\n",
    "#                 board.push(move)\n",
    "#                 eval = self.alphabeta(board, depth - 1, alpha, beta, False)\n",
    "#                 board.pop()\n",
    "#                 max_eval = max(max_eval, eval)\n",
    "#                 alpha = max(alpha, eval)\n",
    "#                 if beta <= alpha:\n",
    "#                     break  # Beta cutoff\n",
    "#             return max_eval\n",
    "#         else:\n",
    "#             min_eval = float('inf')\n",
    "#             for move in board.legal_moves:\n",
    "#                 board.push(move)\n",
    "#                 eval = self.alphabeta(board, depth - 1, alpha, beta, True)\n",
    "#                 board.pop()\n",
    "#                 min_eval = min(min_eval, eval)\n",
    "#                 beta = min(beta, eval)\n",
    "#                 if beta <= alpha:\n",
    "#                     break  # Alpha cutoff\n",
    "#             return min_eval\n",
    "\n",
    "#     def find_best_move(self, board):\n",
    "#         \"\"\"Find the best move for the current position.\"\"\"\n",
    "#         if board.is_game_over():\n",
    "#             return None\n",
    "        \n",
    "#         best_move = None\n",
    "#         best_value = float('-inf') if board.turn == chess.WHITE else float('inf')\n",
    "#         alpha = float('-inf')\n",
    "#         beta = float('inf')\n",
    "        \n",
    "#         for move in board.legal_moves:\n",
    "#             board.push(move)\n",
    "#             value = self.alphabeta(board, self.depth - 1, alpha, beta, not board.turn)\n",
    "#             board.pop()\n",
    "            \n",
    "#             if board.turn == chess.WHITE:  # Maximizing (White)\n",
    "#                 if value > best_value:\n",
    "#                     best_value = value\n",
    "#                     best_move = move\n",
    "#                 alpha = max(alpha, value)\n",
    "#             else:  # Minimizing (Black)\n",
    "#                 if value < best_value:\n",
    "#                     best_value = value\n",
    "#                     best_move = move\n",
    "#                 beta = min(beta, value)\n",
    "        \n",
    "#         return best_move"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7489487,
     "isSourceIdPinned": false,
     "sourceId": 67474,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
