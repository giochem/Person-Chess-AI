{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import chess\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model_architecture.neural_network import NNUE\n",
    "\n",
    "# Encoding functions\n",
    "pieces = list('rnbqkpRNBQKP.')\n",
    "def one_hot_encode_piece(piece):\n",
    "    arr = np.zeros(len(pieces))\n",
    "    piece_to_index = {p: i for i, p in enumerate(pieces)}    \n",
    "    index = piece_to_index[piece]\n",
    "    arr[index] = 1\n",
    "    return arr\n",
    "\n",
    "def encode_board(board):\n",
    "    board_str = str(board).replace(' ', '')\n",
    "    board_list = []\n",
    "    for row in board_str.split('\\n'):\n",
    "        for piece in row:\n",
    "            board_list.append(one_hot_encode_piece(piece))\n",
    "    return np.array(board_list)\n",
    "\n",
    "def encode_fen_string(fen_str):\n",
    "    board = chess.Board(fen=fen_str)\n",
    "    return encode_board(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: (1979383, 2)\n",
      "used shape: (1000, 2)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('../chess-data/fen/train.csv')\n",
    "print('original shape:',df.shape)\n",
    "df = df[:1000]\n",
    "print('used shape:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      r1b2rk1/ppp2pbp/3q1np1/n3p1B1/2B5/1Q3N2/PP1N1P...\n",
       "1      8/1pp2p2/6k1/4P2p/p1PR1K1P/2r2P2/6P1/8 w - - 0 33\n",
       "2      r2qk1nr/1b3pbp/n3p1p1/1pp1P3/p2PN3/2P2N2/PPB3P...\n",
       "3      2b2rk1/5pp1/p2q1n1p/P2pn3/3N4/3BP1B1/2Q2PPP/Rr...\n",
       "4      r2qkb1r/ppp2ppb/2n1p3/3n2PQ/3Pp3/2P4P/PP6/RNB1...\n",
       "                             ...                        \n",
       "995    rnbqk1nr/pppp1ppp/4p3/4P3/1b1P1P2/2P5/PP4PP/RN...\n",
       "996    rR4k1/2p1qp1p/2b1pb2/2Pp2p1/p2P1B2/P1Q1PN2/5PP...\n",
       "997             8/pppnk3/8/7P/8/8/P1P3P1/2KR4 w - - 0 30\n",
       "998    rnbqkb1r/ppp3pp/4pn2/3p1pB1/3PP3/2N2P2/PPP3PP/...\n",
       "999    r1bq1rk1/pp3ppp/5n2/4p3/3n4/1QNP1P2/P3B1PP/R3K...\n",
       "Name: FEN, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoding data...\n",
      "Time elapsed: 0s\n"
     ]
    }
   ],
   "source": [
    "# Encode data\n",
    "print('Encoding data...')\n",
    "st = time.time()\n",
    "df['FEN'] = df['FEN'].apply(encode_fen_string)\n",
    "print(f'Time elapsed: {round(time.time()-st)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "1      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "2      [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "3      [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "4      [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "                             ...                        \n",
       "995    [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "996    [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "997    [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "998    [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "999    [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...\n",
       "Name: FEN, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['FEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# split data and covert tensor for traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: torch.Size([800, 64, 13])\n",
      "X_test shape: torch.Size([200, 64, 13])\n",
      "y_train shape: torch.Size([800])\n",
      "y_test shape: torch.Size([200])\n"
     ]
    }
   ],
   "source": [
    "X = np.stack(df['FEN'].values)  # Convert list of arrays to a single numpy array\n",
    "y = df['Evaluation'].values\n",
    "# Convert to PyTorch tensors\n",
    "X = torch.tensor(X, dtype=torch.float32)  # Shape: (1000, 64, 13)\n",
    "y = torch.tensor(y, dtype=torch.float32)  # Shape: (1000,)\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Verify shapes\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NNUE(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_tanh_stack): Sequential(\n",
       "    (0): Linear(in_features=832, out_features=256, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=64, out_features=8, bias=True)\n",
       "    (5): Tanh()\n",
       "  )\n",
       "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NNUE()\n",
    "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)  # Adam optimizer\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 311926.6219\n",
      "Epoch [2/50], Loss: 311865.4000\n",
      "Epoch [3/50], Loss: 311854.3044\n",
      "Epoch [4/50], Loss: 311845.4650\n",
      "Epoch [5/50], Loss: 311732.7325\n",
      "Epoch [6/50], Loss: 311297.1653\n",
      "Epoch [7/50], Loss: 310955.4009\n",
      "Epoch [8/50], Loss: 310814.5400\n",
      "Epoch [9/50], Loss: 310562.4194\n",
      "Epoch [10/50], Loss: 310338.6353\n",
      "Epoch [11/50], Loss: 310160.1389\n",
      "Epoch [12/50], Loss: 309951.8178\n",
      "Epoch [13/50], Loss: 309769.5081\n",
      "Epoch [14/50], Loss: 309830.1909\n",
      "Epoch [15/50], Loss: 309534.5225\n",
      "Epoch [16/50], Loss: 309403.4875\n",
      "Epoch [17/50], Loss: 309190.6462\n",
      "Epoch [18/50], Loss: 309023.6997\n",
      "Epoch [19/50], Loss: 308859.4398\n",
      "Epoch [20/50], Loss: 308711.4756\n",
      "Epoch [21/50], Loss: 308572.2019\n",
      "Epoch [22/50], Loss: 308436.0381\n",
      "Epoch [23/50], Loss: 308314.9406\n",
      "Epoch [24/50], Loss: 308175.7459\n",
      "Epoch [25/50], Loss: 308040.6097\n",
      "Epoch [26/50], Loss: 307916.2372\n",
      "Epoch [27/50], Loss: 307860.3422\n",
      "Epoch [28/50], Loss: 308172.4678\n",
      "Epoch [29/50], Loss: 307861.3513\n",
      "Epoch [30/50], Loss: 307765.4919\n",
      "Epoch [31/50], Loss: 308072.0242\n",
      "Epoch [32/50], Loss: 307615.7861\n",
      "Epoch [33/50], Loss: 307239.7666\n",
      "Epoch [34/50], Loss: 307136.9562\n",
      "Epoch [35/50], Loss: 306933.1578\n",
      "Epoch [36/50], Loss: 306749.6203\n",
      "Epoch [37/50], Loss: 306678.4437\n",
      "Epoch [38/50], Loss: 306688.5344\n",
      "Epoch [39/50], Loss: 306584.6813\n",
      "Epoch [40/50], Loss: 306263.3006\n",
      "Epoch [41/50], Loss: 306193.3359\n",
      "Epoch [42/50], Loss: 305999.3088\n",
      "Epoch [43/50], Loss: 305849.5759\n",
      "Epoch [44/50], Loss: 305713.9447\n",
      "Epoch [45/50], Loss: 305598.9841\n",
      "Epoch [46/50], Loss: 305460.9684\n",
      "Epoch [47/50], Loss: 305333.7831\n",
      "Epoch [48/50], Loss: 305211.8069\n",
      "Epoch [49/50], Loss: 305091.5963\n",
      "Epoch [50/50], Loss: 304972.0559\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs, targets\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.view(-1, 1))  # Reshape targets to match output\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Print epoch loss\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), \"./checkpoint/nnue_1000data_50epochs.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "torch.Size([1, 64, 13])\n",
      "Test Loss: 437052.2689\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # Set model to evaluation mode\n",
    "test_loss = 0.0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        print(inputs.shape)\n",
    "        inputs, targets = inputs, targets\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.view(-1, 1))\n",
    "        test_loss += loss.item()\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# minimax + nnue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = NNUE()\n",
    "new_model.load_state_dict(torch.load('./checkpoint/nnue_1000data_50epochs.pth', weights_only=True))\n",
    "new_model.eval()\n",
    "\n",
    "fen = '8/1pp2p2/6k1/4P2p/p1PR1K1P/2r2P2/6P1/8 w - - 0 33'\n",
    "fen = np.stack(encode_fen_string(fen))\n",
    "fen = torch.tensor(fen, dtype=torch.float32).unsqueeze(0)\n",
    "fen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chess\n",
    "import torch\n",
    "    \n",
    "class MinimaxNNUE:\n",
    "    def __init__(self, depth=3):\n",
    "        self.depth = depth\n",
    "        self.nnue = NNUE()\n",
    "        self.nnue.load_state_dict(torch.load('./checkpoint/nnue_1000data_50epochs.pth', weights_only=True))\n",
    "        self.nnue.eval()\n",
    "    def evaluate_board(self, board):\n",
    "        \"\"\"Evaluate the board position based on material and piece-square tables.\"\"\"\n",
    "        if board.is_checkmate():\n",
    "            return -10000 if board.turn == chess.WHITE else 10000\n",
    "        if board.is_stalemate() or board.is_insufficient_material():\n",
    "            return 0\n",
    "        \n",
    "        fen = board.fen()\n",
    "        fen = np.stack(encode_fen_string(fen))\n",
    "        fen = torch.tensor(fen, dtype=torch.float32).unsqueeze(0)\n",
    "        score = self.nnue(fen)\n",
    "        return score\n",
    "\n",
    "    def alphabeta(self, board, depth, alpha, beta, maximizing_player):\n",
    "        \"\"\"Minimax with Alpha-Beta pruning.\"\"\"\n",
    "        if depth == 0 or board.is_game_over():\n",
    "            return self.evaluate_board(board)\n",
    "        \n",
    "        if maximizing_player:\n",
    "            max_eval = float('-inf')\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                eval = self.alphabeta(board, depth - 1, alpha, beta, False)\n",
    "                board.pop()\n",
    "                max_eval = max(max_eval, eval)\n",
    "                alpha = max(alpha, eval)\n",
    "                if beta <= alpha:\n",
    "                    break  # Beta cutoff\n",
    "            return max_eval\n",
    "        else:\n",
    "            min_eval = float('inf')\n",
    "            for move in board.legal_moves:\n",
    "                board.push(move)\n",
    "                eval = self.alphabeta(board, depth - 1, alpha, beta, True)\n",
    "                board.pop()\n",
    "                min_eval = min(min_eval, eval)\n",
    "                beta = min(beta, eval)\n",
    "                if beta <= alpha:\n",
    "                    break  # Alpha cutoff\n",
    "            return min_eval\n",
    "\n",
    "    def find_best_move(self, board):\n",
    "        \"\"\"Find the best move for the current position.\"\"\"\n",
    "        if board.is_game_over():\n",
    "            return None\n",
    "        \n",
    "        best_move = None\n",
    "        best_value = float('-inf') if board.turn == chess.WHITE else float('inf')\n",
    "        alpha = float('-inf')\n",
    "        beta = float('inf')\n",
    "        \n",
    "        for move in board.legal_moves:\n",
    "            board.push(move)\n",
    "            value = self.alphabeta(board, self.depth - 1, alpha, beta, not board.turn)\n",
    "            board.pop()\n",
    "            \n",
    "            if board.turn == chess.WHITE:  # Maximizing (White)\n",
    "                if value > best_value:\n",
    "                    best_value = value\n",
    "                    best_move = move\n",
    "                alpha = max(alpha, value)\n",
    "            else:  # Minimizing (Black)\n",
    "                if value < best_value:\n",
    "                    best_value = value\n",
    "                    best_move = move\n",
    "                beta = min(beta, value)\n",
    "        \n",
    "        return best_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Move.from_uci('f2g2')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chessAI = MinimaxNNUE(depth=10)\n",
    "board = chess.Board('7k/8/8/5pp1/5p1P/5P2/5K2/8 w - - 0 1')\n",
    "chessAI.find_best_move(board)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
